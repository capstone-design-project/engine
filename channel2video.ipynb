{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "capstonecore",
   "display_name": "Python 3.8.5  ('capstone': venv)"
  },
  "metadata": {
   "interpreter": {
    "hash": "a680b2670df803462916287d3605e9623f5afa72f41f2b9f130ffe5fc46e8e69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 라벨링된 채널 정보 -> 비디오 100개씩 추출 및 라벨링 적용"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from youtube_crawler import youtubeCrawler\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('APIkey.json') as f:\n",
    "    key = json.load(f);\n",
    "    apikey = key['APIkey'];\n",
    "\n",
    "\n",
    "YC = youtubeCrawler(apikey)\n",
    "\n",
    "channel_df = pd.read_csv('channel_labeled.csv')\n",
    "channel_df\n",
    "\n",
    "video_labeled_df = pd.DataFrame(columns=['video_id', 'difficulty', 'channel_id'])\n",
    "\n",
    "\n",
    "for idx, channelID in enumerate(channel_df['channel_id']):\n",
    "    # if idx != 6: continue\n",
    "    difficulty = channel_df['difficulty'][idx]\n",
    "    try:\n",
    "        new_videos = YC.get_recent_videos(channelID)\n",
    "        for video_id in new_videos:\n",
    "            video_labeled_df.loc[len(video_labeled_df)] = [video_id, difficulty, channelID]\n",
    "        \n",
    "    except:\n",
    "        print('something wrong')\n",
    "        break\n",
    "    print(f'{idx} {channelID} OK')\n",
    "    \n",
    "\n",
    "video_labeled_df.to_csv('video_labeled.csv', sep=',', index=False)\n",
    "\n",
    "    "
   ]
  },
  {
   "source": [
    "# 분석기를 통해 비디오 스크립트 분석 \n",
    "\n",
    " punctuator 가 머신러닝을 통해 작동하므로 적절한 환경에서 실행해야 오래 걸리지 않음"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from core import analyzeAll\n",
    "\n",
    "import json\n",
    "\n",
    "no_caption_videos =[]\n",
    "train_data = pd.DataFrame(columns=['videoId','totalWords','totalUniqueWords','totalSentences','avgSyllPerSec','avgCEFRScore','avgWordCEFR','avgFreqCEFR','readability','avgSentenceLength','uncommonRatio','totalEasyRatio','totalMiddleRatio','totalHardRatio','wordEasyRatio','wordMiddleRatio','wordHardRatio','FreqEasyRatio','FreqMiddleRatio','FreqHardRatio','channelId'])\n",
    "\n",
    "video_labeled = pd.read_csv('video_labeled.csv')\n",
    "for idx,video_id in enumerate(video_labeled['video_id']):\n",
    "    if idx > -1:\n",
    "        print(f'{idx} {video_id} start')\n",
    "        try:\n",
    "            result = analyzeAll(video_id)\n",
    "            no_script_result = json.loads(result)\n",
    "            del no_script_result['script']\n",
    "            train_data.loc[len(train_data)] = no_script_result\n",
    "            channel_id = video_labeled['channel_id'][idx]\n",
    "            print(channel_id)\n",
    "            train_data.loc[len(train_data)-1, 'channelId'] = channel_id\n",
    "        except NotImplementedError:\n",
    "            print(f'{idx} {video_id} no captions')\n",
    "            no_caption_videos.append(video_id)\n",
    "        if idx % 300 == 0:\n",
    "            train_data.to_csv('video_train_upgrade.csv',sep=',',index=False)\n",
    "            print(\"####temp download#########\")\n",
    "        \n",
    "\n",
    "\n",
    "train_data.to_csv('video_train_upgrade.csv',sep=',',index=False)\n",
    "print(no_caption_videos)"
   ]
  },
  {
   "source": [
    "# 난이도 라벨과 분석 결과 합치기"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data0 = pd.read_csv('video_train.csv', sep=',')\n",
    "data1 = pd.read_csv('video_train_1.csv', sep=',')\n",
    "data2 = pd.read_csv('video_train_2.csv', sep=',')\n",
    "data3 = pd.read_csv('video_train_3.csv', sep=',')\n",
    "\n",
    "\n",
    "merge = pd.concat([data0,data1,data2,data3], ignore_index=True)\n",
    "\n",
    "label = pd.read_csv('video_labeled.csv', sep=',')\n",
    "\n",
    "result = pd.merge(merge, label, how='left', left_on='videoId', right_on='video_id')\n",
    "# result.drop(['channel_id', 'video_id'], axis=1, inplace=True)\n",
    "result.to_csv('capstone_train_data.csv', sep=',', index=False)\n"
   ]
  }
 ]
}